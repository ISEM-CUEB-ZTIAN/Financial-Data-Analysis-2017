#+TITLE: Lecture 2: The ARCH Model
#+AUTHOR: Zheng Tian
#+DATE:
#+STARTUP: beamer
#+OPTIONS: toc:1 H:2
#+LATEX_CLASS: beamer
#+LATEX_CLASS_OPTIONS: [presentation,10pt]
#+BEAMER_THEME: CambridgeUS
#+BEAMER_COLOR_THEME: beaver
#+COLUMNS: %45ITEM %10BEAMER_env(Env) %10BEAMER_act(Act) %4BEAMER_col(Col) %8BEAMER_opt(Opt)
#+PROPERTY: BEAMER_col_ALL 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 0.0 :ETC

#+LATEX_HEADER: \usepackage{amsthm}
#+LATEX_HEADER: \usepackage{amsmath}
#+LATEX_HEADER: \usepackage{amssymb}
#+LATEX_HEADER: \usepackage{mathtools}
#+LATEX_HEADER: \newtheorem{mydef}{Definition}
#+LATEX_HEADER: \newtheorem{mythm}{Theorem}
#+LATEX_HEADER: \newcommand{\dx}{\mathrm{d}}
#+LATEX_HEADER: \newcommand{\var}{\mathrm{Var}}
#+LATEX_HEADER: \newcommand{\cov}{\mathrm{Cov}}
#+LATEX_HEADER: \newcommand{\corr}{\mathrm{corr}}
#+LATEX_HEADER: \newcommand{\pr}{\mathrm{Pr}}
#+LATEX_HEADER: \newcommand{\rarrowd}[1]{\xrightarrow{\text{ \textit #1 }}}
#+LATEX_HEADER: \DeclareMathOperator*{\plim}{plim}
#+LATEX_HEADER: \newcommand{\plimn}{\plim_{n \rightarrow \infty}}
#+LATEX_HEADER: \usepackage{booktabs}
#+LATEX_HEADER: \usepackage{color}
#+LATEX_HEADER: \usepackage{caption}
#+LATEX_HEADER: \usepackage{subcaption}
#+LATEX_HEADER: \def\mathbi#1{\textbf{\em #1}}
#+LATEX_HEADER: \setlength{\parskip}{1em}

* The Volatility of Asset Returns

** Volatility is measured with the conditional variance

- Volatility here refers to the *conditional variance* of a time series.

- For a return series {$r_t$}, we are now interested in 
  \[\sigma^2_t = \var(r_t \mid F_{t-1})\]
  where $F_{t-1}$ is the information set at time $t-1$. 

** Characteristics of volatility (1)

1. *There exist volatility clusters.* That is, volatility may be high
   for certain time periods and low for other periods. 
   #+CAPTION: Percentage Change in the NYSE U.S.100 stock price index
   #+NAME: fig:nyse-us-100
   #+ATTR_LATEX: :width 0.7\textwidth
   [[file:img/nyse_us100.png]]
   
** Characteristics of volatility (2)

2. Volatility evolves over time in a continuous manner. That is,
   volatility jumps are rare.
   #+CAPTION: Annualized Growth Rate of Real GDP
   #+NAME: fig:realgdp
   #+ATTR_LATEX: :width 0.7\textwidth
   [[file:img/readgdp.png]]

** Characteristics of volatility (3)

3. Volatility does not diverge to infinity. That is, volatility varies
   within some fixed range. Statistically speaking, this means that
   volatility is often stationary.

\vspace{0.5cm}

4. Volatility seems to react differently to a big price increase or a
   big price drop, referred to as the leverage effect. 

* The Structure of a Volatility Model

** The basic idea of building a volatility model

Consider the log return series {$r_t$}. The basic idea of a volatility
model is 
- {$r_t$} may appear to be either serially uncorrelated or
  serially correlated with a minor order. 
- However, {$r_t$} is a dependent series and the dependence arises
  from its conditional variance.

#+CAPTION: Time plot of monthly log returns of Intel stock from January 1973 to December 2008
#+NAME: fig:intel-return
#+ATTR_LATEX: :width 0.7\textwidth :height 0.4\textheight
[[file:img/intel.png]]

** The sample ACF of {$r_t$} and {$r^2_t$}

#+CAPTION: Sample ACF and PACF of various functions of monthly log stock returns of Intel Corporation from January 1973 to December 2008: (a) ACF of the log returns, (b) ACF of the squared log returns, (c) ACF of the absolute log returns, and (d) PACF of the squared log returns.
#+NAME: fig:acf-intel-return
#+ATTR_LATEX: :width 0.9\textwidth :height 0.5\textheight
[[file:img/acf_intel.png]]

** Decompose $r_t$ into the mean and variance equations

To capture the dependence in a time series through its second moment
but not the mean, we model the mean process and the variance process
separately. 

For a return series {$r_t$}, we can model it as
\begin{equation}
\label{eq:mean-plus-var}
r_t = \mu_t + a_t
\end{equation}
where $\mu_t$ represents the conditional mean and $a_t$ is
modeled to capture the conditional variance.

** The mean equation

\begin{align}
&\mu_t = E(r_t \mid F_{t-1}) = \sum_{i=1}^p \phi_i y_{t-i} - \sum_{i=1}^q \theta_i a_{t-i} \label{eq:mean-equation} \\
&y_t = r_t - \phi_0 - \sum_{i=1}^k \beta_i x_{it} \nonumber
\end{align}
$F_{t-1}$ is the information set at time $t-1$. 

\vspace{0.5cm}

If you combine these two equations, and let $\mu_t = r_t - a_t$, you
will find that it is just an ARMA$(p, q)$ model with additional
regressors $x_{it}$.

** The variance equation

Denote the conditional variance of $r_t$ with $\sigma^2_t$.
\begin{equation*}
\begin{split}
\sigma^2_t = \var(r_t \mid F_{t-1}) &= E\left( (r_t - E(r_t | F_{t-1}))^2 | F_{t-1} \right) \\
&= E\left( (r_t - \mu_t)^2 \mid F_{t-1} \right) \\
&= \var(a_t \mid F_{t-1})
\end{split}
\end{equation*}

** The variance equation (cont'd)

- If we assume that $E(a_t \mid F_{t-1}) = 0$, we can see that
  $\sigma^2_t = E(a^2_t \mid F_{t-1})$. 

- We can use the lagged value of $a^2_t$ to represent the information
  set $F_{t-1}$
  
- The simplest model is a linear model, like the following
  \[ \sigma^2_t = \alpha_0 + \alpha_1 a^2_{t-1} + \cdots + \alpha_m a^2_{t-m} \]

** The procedure of building a volatility model

Building a volatility model for an asset return series consists of
four steps:

1. Specify a mean equation by testing for serial dependence in the
   data and, if necessary, building an econometric model (e.g., an
   ARMA model) for the return series to remove any linear dependence.

3. Use the squared residuals of the mean equation to test for ARCH
   effects.

4. Specify a volatility model if ARCH effects are statistically
   significant, and perform a joint estimation of the mean and
   volatility equations.

5. Check the fitted model carefully and refine it if necessary.

** Testing for the presence of ARCH effect

*** The Ljung-Box test for the series of $a^2_t$

Upon obtaining the residuals from the estimation
of an adequate mean equation, we can use the squared residuals
{$\hat{a}_t^2$} to test the existence of autocorrelation. 
- The Ljung-Box test is used to test the null hypothesis
  $H_0: \rho_1 = \cdots = \rho_m = 0$.
- The $Q(m)$ statistic is
  calculated and compared with the critical value from $\chi^2(m)$
  distribution at the desired significance level.
- The rejection of the
  null hypothesis implies that there is autoregressive conditional
  heteroskedastic (ARCH) effect. 

** The LM test

*** An auxiliary regression
We estimate a AR$(m)$ model regarding {$\hat{a}^2_t$}, that is,
\[ \hat{a}^2_t = \alpha_0 + \alpha_1 \hat{a}_{t-1}^2 + \cdots +
\alpha_m \hat{a}^2_{t-m} + e_t \]

*** The LM test
With this model, we test the joint hypothesis
\[H_0: \alpha_1 = \cdots = \alpha_m = 0 \]
- The LM statistic is $NR^2$ where $N$ is the sample size of this
  regression and $R^2$ is the coefficient of the determination of this
  regression. 
- Given the null hypothesis is true, this statistic follows
  a $\chi^2(m)$ distribution. 

** The LM test (cont'd)

Alternatively, we can use F statistic to test the joint
hypothesis. 
- Let $SSR_0 = \sum_{t=m+1}^{T} (\hat{a}^2_{t} -
  \bar{\omega})^2$, where $\bar{\omega} = (1/T) \sum_{t=1}^T
  \hat{a}^2_t$.
- Let $SSR_1 = \sum_{t=m+1}^T \hat{e}^2_t$ where $\hat{e}_t$ is the
  residuals from the regression. 
- The F statistic is
  \[F = \frac{(SSR_0 - SSR_1)/m}{SSR_1/(T-2m-1)} \sim F(m, T-2m-1)\]
- Rejecting the null hypothesis motivates us to model the possible
  ARCH effect.

** An example

Go back to Figure [[fig:acf-intel-return]]. Since the return series is
already stationary, we directly test the squared return series to
check the ARCH effect. 

- In the LM test of the ARCH effect, $F = 53.62$ and the p value is
  close to zero.
- The Ljungâ€“Box statistics of the $a^2_t$ series also
  shows strong ARCH effects with $Q(12) = 89.85$, the p value of which is
  close to zero.
- Therefore, we can confirm that the return series of
  Intel stock has an ARCH effect, and next we need to model such an
  effect.

* The ARCH Model

** The basic idea of an ARCH model

Consider a series of shocks {$a_t$} in a return series {$r_t$}. The
basic idea of an Autoregressive Conditional Heteroskedasticity (ARCH)
model is

1. the shock $a_t$ of the return series is serially uncorrelated but
   dependent;

2. the dependence of $a_t$ can be modeled through an autoregressive
   process of $a^2_t$. 

** The ARCH(m) model

An ARCH(m) model takes the following form
\begin{equation}
\label{eq:archm}
a_t = \sigma_t \epsilon_t,\; \sigma^2_t = \alpha_0 + \alpha_1 a^2_{t-1} + \cdots + \alpha_m a^2_{t-m}
\end{equation}
where $\epsilon_t \sim i.i.d.(0, 1)$, $\alpha_0 > 0$ and $\alpha_i
\geq 0$ for $i=1, \ldots, m$. 

- The assumption of $\var(\epsilon_t)=1$ is to make the analysis
  regarding the properties of the ARCH(m) model easy;
- The assumption of $\alpha_0 > 0$ and $\alpha_i \geq 0$ is to ensure
  the conditional variance of $a_t$ is positive. 
- $\alpha_1, \ldots, \alpha_m$ should also satisfy some regularity
  conditions to ensure the unconditional variance of $a_t$ is finite. 

** The Properties of an ARCH Model

- Let's take an ARCH(1) model as an example to discuss the properties of
  ARCH model. 
- The goal is to see how such a model can capture the basic idea mentioned
  above and the stylized fact that highly volatile periods tend to be followed by
  high volatility periods. 

Assume an ARCH(1) model as follows
\begin{equation}
\label{eq:arch1}
a_t = \sigma_t \epsilon_t,\; \sigma^2_t = \alpha_0 + \alpha_1 a^2_{t-1},\; \epsilon_t \sim i.i.d.(0, 1)
\end{equation}
where $a_0 > 0$ and $a_1 \geq 0$. 

** The unconditional mean and variance of $a_t$

*** The unconditional mean
\begin{equation*}
E(a_t) & = E(\sigma_t \epsilon_t) = E(\sigma_t) E(\epsilon_t) = 0
\end{equation*}
The second equality is ensured because $\sigma_t$ and $\epsilon_t$ are
independent, and the third equality comes from the assumption of
$E(\epsilon_t)=0$. 

*** The unconditional variance
\begin{equation*}
\begin{split}
\var(a_t) &= E(a^2_t) = E(\sigma^2_t \epsilon^2_t) \\
&= E(\alpha_0 + \alpha_1 a^2_{t-1}) \cdot 1 = \alpha_0 + \alpha_1\var(a_{t-1})
\end{split}
\end{equation*}

Assuming the unconditional mean of $a_t$ is a constant(why?), we can
have 

\[\var(a_t) = \frac{\alpha_0}{1-\alpha_1} \]

Since the variance should be positive and finite, we must have $0 \leq
\alpha_1 < 1$. 

# The reason that we need to assume the unconditional mean of $a_t$ to
# be constant and finite is that we assume the return series {$r_t$}
# itself is constant. Keep in mind that a complete ARCH model also
# includes a mean equation for the return series, say, an ARMA model. 

** The unconditional covariance of $a_t$

Since $\epsilon_t$ and $\epsilon_{t-i}$ for $i \neq 0$ are independent, 

\begin{equation*}
\begin{split}
\cov(a_t, a_{t-i}) &= E(a_t a_{t-i}) = E(\sigma_t \epsilon_t \sigma_{t-i} \epsilon_{t-i}) \\
&= E(\sigma_t \sigma_{t-i}) E(\epsilon_t \epsilon_{t-i}) = 0
\end{split}
\end{equation*}

- What we get now?
  - $a_t$ has constant unconditional mean and variance,
  - $a_t$ is serially uncorrelated. 

** The kurtosis of $a_t$

- Assume that $\epsilon \sim N(0, 1)$, implying that $E(\epsilon^4_t) =
  3$. Thus, we have
  \begin{equation*}
  \begin{split}
  E(a^4_t) &= E(\sigma^4_t \epsilon_t^4) = E(\sigma^4_t) E(\epsilon^4_t) = 3 E(\sigma^4_t) \\
  &= 3\left(\alpha^2_0 + 2\alpha_0\alpha_1 E(a^2_{t-1}) + \alpha^2_1 E(a^4_{t-1}) \right)
  \end{split}
  \end{equation*}

- Assume that $a_t$ is fourth-order stationary so that we can define
  $m_4 = E(a^4_t) = E(a^4_{t-1})$. Then, using the fact that $E(a^2_t) =
  \alpha_0 /(1-\alpha_1)$, we can solve $m_4$ from the
  above equation.
  \[m_4 = \frac{3\alpha^2_0(1+\alpha_1)}{(1-\alpha_1)(1-3\alpha^2_1)}
  \]

** The kurtosis of $a_t$ (cont'd)

This result regarding $m_4$ has two important implications: 
1) Since the fourth moment of $a_t$ is positive, we see that $\alpha_1$ must
   also satisfy the condition $1-3\alpha_1^2 > 0$, that is, $0 \leq
   \alpha^2_1 < \frac{1}{3}$.
2) The kurtosis of $a_t$ is
   \[\text{kurtosis} = \frac{E(a^4_t)}{E(a^2_t)^2} =
   \frac{3(1-\alpha^2_1)}{1-3\alpha_1^2}  > 3\]

   Thus, the the excess kurtosis of $a_t$ is positive and the tail
   distribution of $a_t$ is heavier than that of a normal
   distribution. 

** The conditional mean

- Let's write $E_{t-1}(a_t)$ to represent the conditional mean given the
  information set $F_{t-1}$, i.e., $E(E(a_t \mid F_{t-1}))$. 

- Since $\epsilon_t$ is i.i.d, we have $E_{t-1}(\epsilon_t) =
  E(\epsilon_t) = 0$. Thus, 

  \begin{equation*}
  \begin{split}
  E_{t-1}(a_t) &= E_{t-1}(\sigma_t \epsilon_t) = E_{t-1}\left((\alpha_0 + \alpha_1 a^2_{t-1})^{1/2} \epsilon_t\right) \\
  &= (\alpha_0 + \alpha_1 a^2_{t-1})^{1/2} E_{t-1}(\epsilon_t) = 0
  \end{split}
  \end{equation*}

** The conditional variance

- The conditional variance of $a_t$ is 
  \begin{equation*}
  \begin{split}
  \var_{t-1}(a_t) &= E_{t-1}(a^2_t) = E_{t-1} \left( \sigma^2_t \epsilon_t^2 \right) \\
  &= E_{t-1}\left((\alpha_0 + \alpha_1 a^2_{t-1}) \epsilon^2_t \right) \\ 
  &= E_{t-1}(\alpha_0 + \alpha_1 a^2_{t-1}) E_{t-1}(\epsilon^2_t) \\
  &= (\alpha_0 + \alpha_1 a^2_{t-1}) E(\epsilon^2_t) \\
  &= \alpha_0 + \alpha_1 a^2_{t-1} = \sigma^2_t
  \end{split}
  \end{equation*}

- How does the conditional variance capture the stylized fact?

* Estimation and Forecasting

** Order determination

- Before estimating an ARCH(m) model, we need to determine the order
  $m$.

  \vspace{0.2cm}

- The basic idea is that we treat an ARCH(m) model as an AR process
  of {$a^2_t$}, and apply the partial autocorrelation function (PACF) to
  determine $m$.

** Why using the PACF?

We justify the use of the PACF of {$a^2_t$} to determine $m$ through
two perspectives.

\vspace{0.2cm}

1. We can consider $a^2_t$ as an unbiased estimator of $\sigma^2_t$
   given the sample data because $E_{t-1}(a^2_t) =
   \sigma^2_t$. Therefore, we use $a^2_t$ as an approximate to
   $\sigma^2_t$.

   \vspace{0.2cm}

2. We can define $\eta_t = a^2_t - \sigma^2_t$. It can be shown that
   - $E(\eta_t) = 0$ and $E(\eta_t \eta_{t-s})=0$ for $s > 0$.
   - But $\eta_t$ is not i.i.d. because $a^2_t$ is dependent.

   \vspace{0.2cm}

   So an ARCH(m) model is essentially an AR(m) model, except
   that $\eta_t$ is not i.i.d. That is,
   \[ a^2_t = \alpha_0 + \alpha_1 a^2_{t-1} + \cdots + \alpha_m
   a^2_{t-m} + \eta_t \]


