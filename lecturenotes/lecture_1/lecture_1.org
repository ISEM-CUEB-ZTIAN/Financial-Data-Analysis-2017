#+TITLE: Lecture 1. Review on the Linear Time Series Model
#+OPTIONS: toc:1 H:3 num:2

#+LATEX_CLASS: article
#+LATEX_CLASS_OPTIONS: [a4paper,11pt]
#+LATEX_HEADER: \usepackage[margin=1in]{geometry}
# #+LATEX_HEADER: \usepackage[top=1.5cm, bottom=1.5cm, outer=5cm, inner=2cm, heightrounded, marginparwidth=2.5cm, marginparsep=1cm]{geometry}
#+LATEX_HEADER: \usepackage{setspace}
#+LATEX_HEADER: \onehalfspacing
#+LATEX_HEADER: \usepackage{parskip}
#+LATEX_HEADER: \usepackage{mathtools}
#+LATEX_HEADER: \usepackage{hyperref}
#+LATEX_HEADER: \hypersetup{colorlinks,citecolor=black,filecolor=black,linkcolor=black,urlcolor=black}
#+LATEX_HEADER: \usepackage{graphicx}
#+LATEX_HEADER: \usepackage{tabularx}
#+LATEX_HEADER: \usepackage{color}

#+LATEX_HEADER: \newtheorem{mydef}{Definition}
#+LATEX_HEADER: \newtheorem{mythm}{Theorem}
#+LATEX_HEADER: \newcommand{\dx}{\mathrm{d}}
#+LATEX_HEADER: \newcommand{\var}{\mathrm{Var}}
#+LATEX_HEADER: \newcommand{\cov}{\mathrm{Cov}}
#+LATEX_HEADER: \newcommand{\corr}{\mathrm{Corr}}
#+LATEX_HEADER: \newcommand{\pr}{\mathrm{Pr}}
#+LATEX_HEADER: \newcommand{\rarrowd}[1]{\xrightarrow{\text{ \textit #1 }}}
#+LATEX_HEADER: \DeclareMathOperator*{\plim}{plim}
#+LATEX_HEADER: \newcommand{\plimn}{\plim_{n \rightarrow \infty}}
#+LATEX_HEADER: \usepackage{marginnote}
#+LATEX_HEADER: \newcommand{\mymarginnote}[2]{\marginnote{\setstretch{1.0}\parbox[t]{\marginparwidth}{\scriptsize \textcolor{#1}{#2}}}}
#+LATEX_HEADER: \usepackage{todo}


* Introduction

This lecture reviews what we have learned about the linear time series
models, namely, AR, MA, and ARMA models. These models are the
foundation of what we are going to learn in the following lectures. The
review is far from comprehensive but gives you a big picture regarding
these models and links them with what to be learned next. 


* Financial Time Series Data

This course mainly concerns the time series of the returns to
financial assets. Let $P_t$ be the price of an financial asset at time
$t$. Then, what we are mostly interested is the following

\[ r_t = ln(P_t) - ln(P_{t-1}) \]

$\{r_t\}$ is the series of asset return for $t = 1, \ldots, T$. 


* Weak Stationarity

The foundation of time series analysis is the concept of stationarity. Mostly, we
focus on weak stationarity. 

A series $\{r_t\}$ is weakly stationary if
1) $E(r_t) = \mu < \infty$ where $\mu$ is a constant
2) $\cov(r_t, r_{t-\ell}) = \gamma_{\ell} < \infty$, which only depends on $\ell$. 

It follows that $\var(r_t) = \gamma_0 < \infty$, which is also a
constant. 


* The ACF and the Ljung-Box Test

We can use the autocorrelation function (ACF) to characterize the influence
the past value of the series $r_{t-i}$ for $i = 1, \ldots, T$ on the
current value $r_t$. 

- The lag-\ell ACF of the series $\{r_t\}$ is
  \[ \rho_{\ell} = \frac{\cov(r_t, r_{t-\ell})}{\sqrt{\var(r_t)\var(r_{t-\ell})}} = \frac{\gamma_{\ell}}{\gamma_0} \]

- The sample lag-\ell ACF is computed as 
  \[ \hat{\rho}_{\ell} = \frac{\sum_{t=\ell+1}^T (r_t -
  \bar{r})(r_{t-\ell} - \bar{r})}{\sum_{t=1}^T (r_t - \bar{r})^2},\; 0
  \leq \ell < T-1 \]

- The Ljung-Box test is commonly used to test the existence of
  autocorrelation in $\{r_t\}$. 

  The null hypothesis is 
  \[ H_0: \rho_1 = \cdots = \rho_m = 0,\; H_1: \rho_i \neq 0 \text{
  for some } i \in \{1, \ldots, m\} \]

  The test statistic is 
  \[ Q(m) = T(T+2)\sum_{\ell=1}^m \frac{\hat{\rho}^2_{\ell}}{T-\ell}
  \sim \chi^2(m) \]
  When $Q(m) > \chi^2_{\alpha}$, where $\chi^2_{\alpha}$ is the
  critical value at the significance level of $\alpha$ of a
  chi-squared distribution with $m$ degree of freedom. 
  
** TODO Replicate Figure 2.1 and 2.2


* The Linear Time Series Models

** The ARMA Model

Autoregressive moving-average models $\mathrm{ARMA}(p, q)$
encompass autoregressive models $\mathrm{AR}(p)$ and
moving-average models $\mathrm{MA}(q)$. 

A general $\mathrm{ARMA}(p, q)$ model is in the form of
\begin{equation}
\label{eq:armapq}
r_t = \phi_0 + \sum_{i=1}^p \phi_i r_{t-i} + a_t - \sum_{i=1}^q \theta_i a_{t-i}
\end{equation}
where $\{a_t\}$ is a white noise series, i.e., $a_t \sim
\mathrm{i.i.d.}(0, \sigma^2_a)$. 

From the general $\mathrm{ARMA}(p, q)$ model, we know that $\mathrm{AR}(p)$ models are
simply $\mathrm{ARMA}(p, 0)$ and $\mathrm{MA}(q)$ models are $\mathrm{ARMA}(0, q)$ for $p, q >
0$. 

What we are interested in these models can be summarized by the
following items:
- The stationarity condition
- The statistical properties
  - The unconditional mean, $E(r_t)$
  - The unconditional variance, $\var(r_t)$. 
  - The ACF, $\rho_{\ell}$ for $\ell > 0$.
- Estimation and model checking
- Forecasting


** The stationarity condition

- The characteristic equation of all $\mathrm{ARMA}(p, q)$ models is
  \begin{equation}
  \label{eq-chareq}
  \alpha^p + \phi_1 \alpha^{p-1} + \cdots + \phi_p = 0
  \end{equation}
  The solutions to this equation are the characteristic roots. 

- The weak stationarity requires that the characteristic roots be less
  than one in modulus. 
  - If the root is a real number, $\alpha^{*}$, then weak stationarity
    requires $|\alpha^{*}| < 1$.
  - If the root is a complex number, $\alpha^{*} = a + bi$ where $i =
    \sqrt{-1}$, then weak stationarity requires $r = \sqrt{a^2 + b^2} < 1$.

- $\mathrm{AR}(p)$ and $\mathrm{ARMA}(p,q)$ share the same
  characteristic equation as Equation eqref:eq-chareq so that their
  stationarity conditions are also the same.

- $\mathrm{MA}(q)$ models are always weakly stationary as long as the
  $\{a_t\}$ series is white noise.

*** TODO Draw a unit circle


** The AR Model

We review the properties of $\mathrm{AR}(p)$ model using the simple
$\mathrm{AR}(1)$ process, 
\begin{equation}
\label{eq-ar1}
r_t = \phi_0 + \phi_1 r_{t-1} + a_t,\; a_t \sim i.i.d.(0, \sigma^2_a)
\end{equation}

*** The stationarity condition

The characteristic equation of Equation eqref:eq-ar1 is
\[ \alpha - \phi_1 = 0 \]
The characteristic root is simply $\alpha = \phi_1$. Thus, the
stationarity condition of an $\mathrm{AR}(1)$ process is
$|\phi_1|<1$. 

Remember that when we derive the unconditional mean, variance and ACF
of $r_t$, we always assume that $\{r_t\}$ is weakly stationary that is
$|\phi_1| < 1$. 

*** The expectations

- The unconditional mean of $r_t$ is
  \[ E(r_t) = \mu = \frac{\phi_0}{1 - \phi_1} \]
  Because $\{r_t\}$ is weakly stationary, its mean is constant over
  time. 
  
- The conditional mean of $r_t$ given the information at $t-1$ is
  \[ E(r_t \mid r_{t-1}) = \phi_0 + \phi_1 r_{t-1} \]

*** The variance 

- The unconditional variance of $r_t$ is 
  \[ \var(r_t) = \frac{\sigma^2_a}{1 - \phi_1^2} \]
  The unconditional variance is also a constant because of weak
  stationarity. The existence of the unconditional mean and variance
  of $r_t$ requires $|\phi_1| < 1$, which is also the sufficient
  condition for weak stationarity. 

- The conditional variance of $r_t$ given $r_{t-1}$ is
  \[ \var(r_t \mid r_{t-1}) = \var(a_t) = \sigma^2_a \]

*** The ACF

The ACF of $\mathrm{AR}(1)$ is
\[\rho_0 = 1,\; \rho_{\ell} = \phi_1 \rho_{\ell-1}, \text{ for }
\ell>0 \]
It says that the ACF of a weakly stationary AR(1) series decays
exponentially with rate $\phi_1$ and starting value $\rho_0=1$. 

**** TODO Insert Figure 2.3

*** The ACF for the general AR(p) model

For a general $AR(p)$ model, 
\begin{equation}
\label{eq-arp}
r_t = \phi_0 + \sum_{i=1}^p \phi_i r_{t-i} + a_t,\; a_t \sim i.i.d.(0, \sigma^2_a)
\end{equation}

- The unconditional mean is 
  \[ E(r_t) = \frac{\phi_0}{1 - \sum_{i=1}^p \phi_i} \]

- The ACF of {$r_t$} is governed by the following difference equation
  \[ \rho_{\ell} = \phi_1 \rho_{\ell-1} + \phi_2 \rho_{\ell-2} +
  \cdots + \rho_{\ell-p} \]
  Rewritten with the lag operator $B$, we have
  \[ (1 - \phi_1 B - \cdots - \phi_p B^p) \rho_{\ell} = 0 \]
  where $1 - \phi_1 B - \cdots - \phi_p B^p=0$ is the inverse
  characteristic equation. 

- An $\mathrm{AR}(p)$ series is weakly stationary when all the roots
  of the inverse characteristic equation are greater than one in
  modulus. 


** TODO The MA Model



* TODO Random Walk and Unit-Root Nonstationarity



* TODO The Basic R functions for Financial Data

